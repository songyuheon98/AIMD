{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12103 images belonging to 10 classes.\n",
      "Found 3031 images belonging to 10 classes.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8d4d31d98c75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgeneration\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_generations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0mfitness_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_population\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 이전 코드와 동일합니다.\n",
    "# 공통 -------------------------------------------------------------\n",
    "data_path = \"F:/MALWARE-CLASSIFICATION/TRAIN/TRAIN_TEST_CLASSF/\"\n",
    "train_path = os.path.join(data_path, \"train\")\n",
    "test_path = os.path.join(data_path, \"test\")\n",
    "\n",
    "model_len=50\n",
    "learn_rate = 0.001\n",
    "\n",
    "# ResNet & Dense 121 개별 =======================\n",
    "# 이미지 크기와 배치 크기 지정\n",
    "img_width, img_height = 256, 256\n",
    "batch_size = 16\n",
    "\n",
    "# 데이터 제너레이터 생성\n",
    "train_datagen = ImageDataGenerator()\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "# 데이터 불러오기\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "def train_model(model, train_generator, test_generator, learn_rate, model_len, model_name, model_save_path):\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(learning_rate=learn_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습 중간에 accuracy와 loss 값을 저장할 콜백 함수 정의\n",
    "    os.makedirs(model_save_path, exist_ok=True)\n",
    "\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=f'{model_save_path}'+'model_weights{epoch}.h5', \n",
    "                                                    save_weights_only=True, \n",
    "                                                    save_freq='epoch',\n",
    "                                                    verbose=1)\n",
    "    history = tf.keras.callbacks.History()\n",
    "\n",
    "    # 모델 학습\n",
    "    model.fit(train_generator, epochs=model_len, validation_data=test_generator,\n",
    "              callbacks=[checkpoint, history])\n",
    "\n",
    "    # 학습 결과 시각화\n",
    "    plot_history(history, model_name, model_save_path)\n",
    "    \n",
    "def plot_history(history,model_name,model_save_path):\n",
    "    # accuracy와 loss 값을 가져오기\n",
    "    acc_list = history.history['accuracy']\n",
    "    val_acc_list = history.history['val_accuracy']\n",
    "    loss_list = history.history['loss']\n",
    "    val_loss_list = history.history['val_loss']\n",
    "\n",
    "    # accuracy와 loss 값을 그래프로 출력\n",
    "    plt.plot(acc_list)\n",
    "    plt.plot(val_acc_list)\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(loss_list)\n",
    "    plt.plot(val_loss_list)\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    data=[ history.history['accuracy'],history.history['val_accuracy'],\n",
    "          history.history['loss'],history.history['val_loss']]\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    df.to_csv(f'{model_save_path}accuracy_loss.csv', index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# ===================================\n",
    "\n",
    "\n",
    "\n",
    "# 진화 알고리즘 구현\n",
    "def create_initial_population(population_size, bounds):\n",
    "    return np.random.uniform(bounds[:, 0], bounds[:, 1], size=(population_size, len(bounds)))\n",
    "\n",
    "def evaluate_population(population, train_generator, test_generator, model):\n",
    "    fitness_scores = []\n",
    "    for individual in population:\n",
    "        learn_rate, model_len = individual\n",
    "        model_len = int(model_len)\n",
    "        train_model(model, train_generator, test_generator, learn_rate, model_len)\n",
    "        accuracy = model.evaluate(test_generator)[1]\n",
    "        fitness_scores.append(accuracy)\n",
    "    return np.array(fitness_scores)\n",
    "\n",
    "def select_parents(population, fitness_scores, num_parents):\n",
    "    parents = population[np.argsort(-fitness_scores)][:num_parents]\n",
    "    return parents\n",
    "\n",
    "def crossover(parents, offspring_size):\n",
    "    offspring = np.empty(offspring_size)\n",
    "    for i in range(offspring_size[0]):\n",
    "        parent1_idx = i % parents.shape[0]\n",
    "        parent2_idx = (i + 1) % parents.shape[0]\n",
    "        crossover_point = random.randint(0, parents.shape[1] - 1)\n",
    "        offspring[i, :crossover_point] = parents[parent1_idx, :crossover_point]\n",
    "        offspring[i, crossover_point:] = parents[parent2_idx, crossover_point:]\n",
    "    return offspring\n",
    "\n",
    "def mutation(offspring, bounds, mutation_rate):\n",
    "    for idx in range(offspring.shape[0]):\n",
    "        for param_idx in range(offspring.shape[1]):\n",
    "            if np.random.rand() < mutation_rate:\n",
    "                random_value = np.random.uniform(bounds[param_idx, 0], bounds[param_idx, 1])\n",
    "                offspring[idx, param_idx] = random_value\n",
    "    return offspring\n",
    "\n",
    "def evaluate_population(population, train_generator, test_generator):\n",
    "    fitness_scores = []\n",
    "    for individual in population:\n",
    "        learn_rate, model_len = individual\n",
    "        model_len = int(model_len)\n",
    "\n",
    "        # 모델 정의\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(256, 256, 3)),\n",
    "            layers.AveragePooling2D(),\n",
    "            layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'),\n",
    "            layers.AveragePooling2D(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(units=120, activation='relu'),\n",
    "            layers.Dense(units=84, activation='relu'),\n",
    "            layers.Dense(units=10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        train_model(model, train_generator, test_generator, learn_rate, model_len)\n",
    "        accuracy = model.evaluate(test_generator)[1]\n",
    "        fitness_scores.append(accuracy)\n",
    "    return np.array(fitness_scores)\n",
    "\n",
    "\n",
    "\n",
    "# 진화 알고리즘 설정\n",
    "num_generations = 10\n",
    "population_size = 20\n",
    "num_parents = 10\n",
    "mutation_rate = 0.1\n",
    "bounds = np.array([[1e-4, 1e-2], [10, 100]])\n",
    "\n",
    "# 진화 알고리즘 실행\n",
    "population = create_initial_population(population_size, bounds)\n",
    "best_individual = None\n",
    "best_fitness = -np.inf\n",
    "\n",
    "for generation in range(num_generations):\n",
    "    fitness_scores = evaluate_population(population, train_generator, test_generator)\n",
    "\n",
    "\n",
    "\n",
    "# 최적의 하이퍼파라미터로 최종 모델 학습\n",
    "best_learn_rate, best_model_len = best_individual\n",
    "best_model_len = int(best_model_len)\n",
    "print(f\"Best hyperparameters: learning rate: {best_learn_rate}, model length: {best_model_len}\")\n",
    "\n",
    "model_name = 'LeNet'\n",
    "model_save_path = f\"F:/model_save/{model_name}/\"\n",
    "\n",
    "# LeNet 모델 정의\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(256, 256, 3)),\n",
    "    layers.AveragePooling2D(),\n",
    "    layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'),\n",
    "    layers.AveragePooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=120, activation='relu'),\n",
    "    layers.Dense(units=84, activation='relu'),\n",
    "    layers.Dense(units=10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 최적의 하이퍼파라미터를 사용하여 모델 학습\n",
    "train_model(model, train_generator, test_generator, best_learn_rate, best_model_len, model_name, model_save_path)\n",
    "\n",
    "# 예측을 위한 이미지 로드\n",
    "image_path = \"F:/MALWARE-CLASSIFICATION/TRAIN/TRAIN_TEST_CLASSF/test/0/0_0.png\"\n",
    "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array /= 255.\n",
    "\n",
    "# 예측\n",
    "prediction = model.predict(img_array)\n",
    "print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
